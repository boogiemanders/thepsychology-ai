# Overview of Inferential Statistics


**Probability Theory and Sampling Distributions:** Inferential statistics are used to determine if the results of a research study are due to the effects of an independent variable on a dependent variable or to sampling error and involve using an inferential statistical test to compare the obtained sample value to the values in an appropriate sampling distribution. When the sample value of interest is a mean, the appropriate sampling distribution is a sampling distribution of means. It’s the distribution of mean scores that would be obtained if a very large number of same-sized samples were randomly drawn from the population, and the mean score on the variable of interest was calculated for each sample. While many of the sample means would be equal to the population mean, some of the samples would have higher or lower means because of the effects of sampling error, which is a type of random error. In other words, the sample means would vary, not because individuals in the samples were exposed to the independent variable, but because of the effects of sampling error.

In inferential statistics, a sampling distribution of means is not actually constructed by obtaining a large number of random samples from the population and calculating each sample’s mean. Instead, probability theory – and, more specifically, the *central limit theorem* – is used to estimate the characteristics of the sampling distribution. The central limit theorem makes three predictions about the sampling distribution of means: (a) The sampling distribution will increasingly approach a normal shape as the sample size increases, regardless of the shape of the population distribution of scores. (b) The mean of the sampling distribution of means will be equal to the population mean. (c) The standard deviation of the sampling distribution – which is referred to as the standard error of means – will be equal to the population standard deviation divided by the square root of the sample size.
**Null and Alternative Hypothesis**: To use inferential statistics to test a hypothesis about the relationship between independent and dependent variables, the verbal hypothesis about the relationship must be converted to two statistical hypotheses: the null hypothesis and the alternative hypothesis. The *null hypothesis* is stated in a way that indicates that the independent variable does <u>not</u> have an effect on the dependent variable, while the *alternative hypothesis* is stated in a way that indicates that the independent variable <u>does</u> have an effect on the dependent variable. The alternative hypothesis is usually most similar to the verbal hypothesis.   

**Decision Errors:** Because inferential statistics is based on probability theory, when a researcher makes a decision to retain or reject the null hypothesis based on the results of an inferential statistical test, it’s not possible to be certain whether the decision is correct or incorrect. For the EPPP, you want to be familiar with the two possible correct decisions and the two possible <u>in</u>correct decisions: With regard to <u>correct</u> decisions, a researcher can either retain a true null hypothesis or reject a false null hypothesis. When a researcher retains a true null hypothesis, he or she has correctly concluded that the independent variable has not had a significant effect on the dependent variable and that any observed effect is due to sampling error or other factors.  And when a researcher rejects a false null hypothesis, the researcher has correctly concluded that the independent variable has had a significant effect on the dependent variable.

With regard to <u>incorrect</u> decisions, a researcher can either reject a true null hypothesis or retain a false null hypothesis. When a researcher rejects a true null hypothesis, the researcher has concluded that the independent variable has had a significant effect on the dependent variable, but the observed effect is actually due to sampling error or other factors. This type of incorrect decision is known as a Type I error. For the EPPP, you want to know that the probability of making a Type I error is equal to alpha, which is also known as the level of significance and is set by a researcher before analyzing the data he/she has collected.  Alpha is usually set at .05 or .01:  When it’s .05, this means there’s a 5% chance of making a Type I error; when it’s .01, this means there’s a 1% chance of making a Type I error. 

The second type of incorrect decision occurs when a researcher retains a false null hypothesis. In other words, the researcher has concluded that the independent variable has <u>not</u> had a significant effect on the dependent variable when it actually has, but the researcher was not able to detect the effect because of sampling error or other factors. This type of incorrect decision is referred to as a Type II error. The probability of making a Type II error is equal to beta which is <u>not</u> set by the researcher but can be reduced by increasing statistical power. 

**Statistical Power:** Statistical power refers to the ability to reject a false null hypothesis and is affected by several factors: One factor is the size of alpha: The larger the size of alpha, the greater the power. However, alpha is kept small to reduce the probability of making a Type I error, which is why it’s usually set at .01 or .05 rather than at a larger value. A second factor is the size of the effect of the independent variable on the dependent variable: An independent variable is more likely to have a significant effect when it’s of sufficient magnitude and is administered for a sufficient length of time. A third factor is the sample size: The larger the sample, the greater the power. A fourth factor is the type of inferential statistical test that’s used to analyze the data. Parametric tests are more powerful than nonparametric tests, but they can be used only when the data to be analyzed are interval or ratio data and certain assumptions are met. The t-test and analysis of variance are parametric tests and are more powerful than the chi-square test, which is a nonparametric test that’s used to analyze nominal data. Finally, a fifth factor is population homogeneity: The more homogeneous the population is with regard to status or scores on the dependent variable, the more homogeneous the groups drawn from that population will be and, consequently, the easier it will be to detect group differences on the dependent variable that are due to the effects of the independent variable. (Note that, unlike the first four factors, population homogeneity cannot be controlled by the researcher.)

**Bayesian Statistics:** The approach to data analysis described above is referred to as frequentist (or classical) statistics. Although it continues to dominate the analysis of research results in the field of psychology, an alternative method of analysis known as Bayesian statistics has become increasingly popular since the 1990s  (van de Schoot et al., 2017). While frequentist analysis involves drawing conclusions about a parameter (e.g., mean, variance, regression coefficient) from data collected in a current study, Bayesian analysis involves a knowledge-building process in which updated knowledge about a parameter is derived by combining information from data collected in a current study with previous information about that parameter (e.g., Johnson, Ott, & Dogucu, 2022). The two approaches also differ in a number of other ways, including how they conceptualize probability: Frequentist statistics defines probability as the frequency of times a parameter is expected to occur with repeated measurement when the conditions of measurement are held constant. In contrast, Bayesian statistics adopts a subjective approach and defines probability as the degree of belief (certainty) about the occurrence of the parameter. This difference is reflected in the difference between *frequentist confidence intervals* and *Bayesian credibility intervals*: For example, the correct interpretation of a 95% confidence interval for a mean is that, if the study were repeatedly replicated with different samples from the same population and a 95% frequentist confidence interval was calculated for each sample mean, 95% of the confidence intervals would contain the true population mean. In contrast, the correct interpretation of a 95% Bayesian credibility interval is that there is a 95% chance that the true population mean is within the upper and lower limits of the interval. (Note that frequentist confidence intervals are often erroneously interpreted in the correct way for interpreting Bayesian credibility intervals.) 
Bayesian analysis utilizes Bayes’ theorem to use previous knowledge (the prior) and current data (the likelihood function) to derive updated knowledge (the posterior): The prior is the probability distribution for a parameter before collecting new data. The *prior* is chosen by the researcher and is usually based on previous research. The *likelihood function* is the probability distribution derived from data collected in the current study. The *posterior* is the updated probability distribution for the parameter that is obtained by synthesizing the prior distribution and likelihood function. It is used to draw conclusions about the study’s hypothesis and may become the prior in subsequent research. 

Advocates of Bayesian statistics point out the problems with frequentist statistics (e.g., misinterpretation of p-values and confidence intervals) and the advantages of Bayesian statistics, which include providing a method for obtaining updated knowledge about a parameter by combining previous knowledge with current data and allowing researchers to test research hypotheses directly (rather than trying to reject the null hypothesis). In addition, user-friendly software (e.g., JASP) is available for conducting Bayesian hypothesis testing using Bayesian versions of the t-test, ANOVA, correlation, regression, and other methods of statistical analysis. A major criticism of Bayesian statistics is the subjectivity of the prior: As noted by Hackenberger (2019), “there is no single, prescribed and well-defined method for choosing a prior … [and, as a result,] different people can use different priors for the same experiment and thus obtain different posteriors and make different conclusions” ( p. 51).

