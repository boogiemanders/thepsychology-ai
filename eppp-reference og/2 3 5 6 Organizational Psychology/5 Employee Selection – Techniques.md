# Employee Selection – Techniques

**Employee Selection – Techniques

Types of Selection Techniques:** Selection techniques are often referred to as predictors. Commonly used predictors in organizations include interviews, general mental ability tests, personality tests, integrity tests, work samples, assessment centers, and biographical information.
1. **Interviews:** Interviews can be unstructured or structured. When conducting an unstructured interview, interviewers can ask whatever questions they want to ask and do not necessarily ask all applicants the same questions. When conducting a structured interview, all interviewees are asked the same questions that may be derived from the results of a job analysis and scored using a standardized scoring key. In the past, research consistently found structured interviews to be the better predictors of job performance. However, recent studies using statistical methods that provide a more accurate estimate of interview validity have found that structured and unstructured interviews have the same average validity coefficient (.58) and that structured and unstructured interviews are the second most valid predictors of job performance after general mental ability tests (Oh, Postlethwaite, & Schmidt, 2013; Schmidt, Oh, & Shaffer, 2016).

Behavioral and situational interviews are types of structured interviews: *Behavioral interviews* are based on the assumption that past behavior is the best predictor of future behavior and consist of questions that ask interviewees how they responded to specific job-related situations in the past. *Situational interviews* are future-oriented and consist of questions that ask interviewees how they would respond to hypothetical situations. In contrast to an earlier meta-analysis that found behavioral interviews to be the better predictors of job performance, a more recent meta-analysis found that, when behavioral and situational interview questions were written so they assessed the same job requirements and were asked of the same job applicants, situational questions were more valid predictors of job performance than were behavioral questions, suggesting that intentions are more predictive than past behaviors of future behaviors (Culbertson, Weyhrauch, & Huffcutt, 2017; Taylor & Small, 2002).

2. **General Mental Ability Tests:** General mental ability tests are also known as general cognitive ability tests and intelligence tests. They have been found to be the most valid predictors of job performance across a variety of jobs, performance criteria, and organizations (Hunter & Schmidt, 2004; Schmidt & Hunter, 1998; Schmidt, Oh, & Shaffer, 2016). A disadvantage of these tests is that they are associated with a greater risk than other predictors for having an adverse impact on job applicants belonging to some ethnic/racial minority groups.

3. **Personality Tests:** Many personality tests used to facilitate selection decisions in organizations assess the Big Five personality traits – i.e., conscientiousness, openness to experience, extraversion, agreeableness, and emotional stability. Of these traits, conscientiousness has been found to be the best predictor of job performance across different jobs and different performance criteria (Schmidt & Hunter, 1998).

4. **Integrity Tests:** Integrity tests are used to predict whether an applicant is likely to engage in counterproductive behaviors. There are two basic types of integrity tests: Overt integrity tests ask directly about attitudes toward and previous history of dishonesty and theft, while personality-based integrity tests assess aspects of personality that have been linked to dishonesty, disciplinary problems, sabotage, and other counterproductive behaviors. Integrity tests do not seem to have an adverse impact for racial/ethnic minorities. In addition, they have been found to be good predictors of counterproductive behaviors and job performance, with overt tests being better predictors of counterproductive behaviors and personality-based tests being better predictors of job performance (Gatewood, Feild, & Barrick, 2016; Heneman, Judge, & Kammeyer-Mueller, 2014). Schmidt, Oh, and Shaffer’s (2016) meta-analysis of research on selection methods found that integrity tests were the fourth most valid method after general mental ability tests, interviews, and job knowledge tests. These investigators also compared the gain in validity (incremental validity) obtained when a general mental ability test was combined with another selection method and found that combining a general mental ability test with an integrity test produced the greatest gain.

5. **Work Samples:** Work samples require job applicants to perform on-the-job tasks or activities in realistic conditions. In their frequently cited meta-analysis, Schmidt and Hunter (1998) reported an average validity coefficient for work samples that was slightly higher than the coefficient for general mental ability tests. However, the more recent meta-analysis by Schmidt, Oh, & Shaffer (2016) found a lower validity coefficient for work samples than for general mental ability tests, interviews, integrity tests, and several other selection methods. They note that this decrease in validity has been attributed to the fact that, in the past, work samples were used primarily as a selection method for manual skilled jobs but are now increasingly used for jobs in the service sector and may be less accurate for those jobs. 

While traditional work sample tests are appropriate for experienced applicants, *trainability work sample tests* are useful for applicants who do not have previous job experience. They incorporate periods of training and evaluation and are useful for determining if inexperienced applicants are likely to benefit from training. Work samples are often included as part of a *realistic job preview* (RJP), which involves informing job applicants about the positive and negative aspects of the job to reduce the risk for turnover after applicants are hired by ensuring they have realistic job expectations.

6. **Assessment Centers:** Assessment centers are most often used to evaluate candidates for managerial-level jobs and involve having multiple raters rate candidates on several performance dimensions using multiple methods. Methods include personality and ability tests, structured interviews, and simulations (work samples). The in-basket exercise and leaderless group discussion are two of these simulations: The in-basket exercise is used to assess decision-making skills and requires participants to respond to memos, phone messages, and other communications that are similar to those they would encounter on-the-job. The leaderless group discussion is used to evaluate the leadership potential of participants and requires a small group of participants to work together without an assigned leader to solve a job-related problem.

7. **Biographical Information:** When items included in a measure of biographical information have been chosen because they predict job performance, the measure is referred to as a biodata form (or just biodata) or as a biographical information blank (BIB). Empirically derived items not only ask about an applicant’s education and work history but also about family history, health history, interests, social relationships, and other issues. Questions are presented in a multiple-choice format or other format that can be easily scored. Biodata has been found to be a good predictor of performance for a variety of jobs, ranging from unskilled jobs to managerial- and executive-level jobs (e.g., Schmidt, Oh, & Shaffer, 2016). A disadvantage of biodata is that, even though items have been found to be job-related, some may lack face validity – i.e., they don’t “look like” they are asking about attributes or experiences that are related to job performance. As a result, applicants may consider them to be irrelevant to job performance and an invasion of their privacy and refuse to answer them.

**Combining Selection Techniques:** No single predictor is likely to be adequate for making accurate hiring decisions, and organizations ordinarily use multiple predictors. The methods for combining information obtained from multiple predictors are divided into two types – compensatory and noncompensatory: *Compensatory methods* are appropriate when a high score on one or more predictors can compensate for a low score on another predictor. Included in this category are clinical prediction and multiple regression: Clinical prediction relies on the subjective judgment of decision makers, who use their familiarity with job requirements to determine if an applicant’s predictor scores qualify the applicant for the job. The major disadvantage of this method is that it’s susceptible to biases and errors, and the studies have confirmed that statistical methods for combining scores are more accurate than clinical prediction for predicting job performance.  Multiple regression is a statistical method for combining scores. When using this method, each predictor is weighted on the basis of its correlations with the other predictors and with the criterion and the weighted predictor scores are combined to obtain an estimated criterion score.

*Noncompensatory methods* are used when a low score on one predictor cannot be compensated for by a high score on another predictor. Included in this category are multiple cutoff and multiple hurdles. When using multiple cutoff, all of the predictors are administered to all applicants, and applicants must obtain a score that’s above the cutoff score on each predictor to be considered for the job.  Multiple hurdles is similar to multiple cutoff except that predictors are administered in a prespecified order and the applicant must obtain a score above the cutoff on each predictor in order for the next predictor to be administered. Multiple hurdles is preferable to multiple cutoff when it would be too costly to administer all of the predictors to all applicants. Multiple cutoff and multiple hurdles can be combined with multiple regression by using multiple regression to predict the criterion scores of applicants who score above the cutoff score on all of the predictors.  
