# Job Analysis and Performance Assessment


**Job Analysis, Competency Modeling, and Job Evaluation:**  Job analysis, competency modeling, and job evaluation overlap somewhat in their functions and procedures but serve distinct purposes in organizations.

1. **Job Analysis:** Job analysis is a systematic procedure for “identifying how a job is performed, the conditions under which it is performed, and the personal requirements it takes to perform the job” (Aamodt, 2013, p. 599).  A job analysis serves several functions in organizations including obtaining the information needed to write a job description, develop or identify appropriate job performance and selection measures, determine training needs, and make decisions about job design and redesign.  Methods of obtaining information include observing employees while they perform the job; interviewing employees and supervisors about the job; having employees, supervisors, and others familiar with the job complete surveys and questionnaires; and using electronic performance monitoring.

A job analysis may be work-oriented or worker-oriented: A *work-oriented job analysis* focuses on the tasks that must be accomplished to achieve desired job outcomes. Task analysis is a work-oriented approach that involves having employees and supervisors develop a comprehensive list of job tasks, having subject matter experts rate the identified tasks in terms of frequency and importance, and then including tasks with high ratings in the job description. A *worker-oriented job analysis* focuses on the knowledge, skills, abilities, and other characteristics (KSAOs) that are required to accomplish job tasks. The Position Analysis Questionnaire (PAQ) is a worker-oriented job analysis questionnaire that addresses six categories of work activity: information input, mental processes, work output, relationships with other people, job context, and other characteristics.

2. **Competency Modeling:** Competency modeling is similar to job analysis but is somewhat different in focus. While job analysis focuses on the tasks and/or worker characteristics required to perform a specific job successfully, competency modeling is always worker-oriented and focuses on the core competencies (attributes) that are required to successfully perform all jobs or a subset of jobs within an organization and that are linked to the organization’s values, goals, and strategies. “Exhibiting the highest level of professional integrity at all times” and “staying current with the latest technological advances” are examples of core competencies” (Muchinsky, 2012, p. 78).  Competency modeling, like job analysis, serves several functions in organizations, including identifying appropriate job selection and performance measures, determining the content of training programs, and identifying future job requirements.

3. **Job Evaluation:** Job analysis is ordinarily the first step in job evaluation, but a job evaluation is conducted specifically to facilitate decisions related to compensation. It’s often used to establish comparable worth, which is the principle that workers performing jobs that require the same skills and responsibilities or that are of comparable value to the employer should be paid the same. Comparable worth has been applied primarily to the gender gap in wages.

The point system is a commonly used method of job evaluation. It involves determining the monetary value of a job by assigning points to the job’s “compensable factors” (e.g., effort, skill, responsibility, working conditions), summing the points to derive a total score, and using the total score to determine the appropriate compensation for the job.

**Performance Assessment – Criterion Measures:** Measures of job performance are also referred to as criterion measures. They serve several functions in organizations, including providing employees with feedback about their performance and evaluating employee performance to obtain the information needed to make decisions about raises, promotions, etc.

1. **Types of Performance Appraisal Measures:** Performance appraisal measures are categorized as objective or subjective: *Objective measures* usually provide quantitative information and include direct measures of productivity and number of errors, accidents, and absences. Objective measures can provide important information, but they’re not available for certain jobs, they don’t always provide complete information about employee performance, and they can be affected by situational factors such as inadequate resources or support. *Subjective measures* take the form of performance ratings and are the most commonly used performance measures in organizations. Advantages of subjective measures are that they can provide information on aspects of performance that cannot be assessed with an objective measure, they allow raters to take situational factors that affect performance into account, and they can provide information that’s useful for giving employees feedback about their performance. A major disadvantage is that they can be affected by rater biases and errors.

2. **Subjective Rating Scales:** There are two types of subjective rating scales – relative and absolute. *Relative rating scales* require the rater to evaluate an employee by comparing the employee to other employees, while *absolute rating scales* require the rater to evaluate an employee without considering the performance of other employees. Relative rating scales include the paired comparison technique and the forced distribution method:
(a) When using the *paired comparison technique*, the rater compares each employee to all other employees in pairs on each dimension of job performance (e.g., work quality, job knowledge, communication) by indicating which employee is best. An advantage of this technique is that it alleviates central tendency, leniency, and strictness rater biases; a disadvantage is that it can be very time-consuming to use when there are many employees to rate.
(b) The *forced distribution method* requires the rater to assign a certain percent of employees to prespecified performance categories for each dimension of job performance. For example, it might require that 10% of employees be assigned to the poor performance category, 20% to the below average performance category, 40% to the average performance category, 20% to the above average performance category, and 10% to the excellent performance category. The forced distribution method alleviates central tendency, leniency, and strictness rater biases, but it provides inaccurate information when the performance of employees does not match the prespecified categories (e.g., when all employees are performing at the average or above average level).
Absolute rating scales include the critical incident technique, graphic rating scales, and behaviorally anchored rating scales:

(a) The *critical incident technique* (CIT) is a method of both job analysis and performance assessment. It involves identifying employee behaviors that are associated with exceptionally poor and exceptionally good performance by observing employees while they work or by interviewing people familiar with the job. The list of “critical incidents” is then used to evaluate performance by checking those that apply to each employee. An advantage of CIT is that it provides useful information for employee feedback because it focuses on observable behaviors.  Disadvantages are that it can be time-consuming to develop, it focuses on extreme (rather than typical) behaviors, and it’s job-specific, which means that new critical incidents must be identified for different jobs.

(b) When using a *graphic rating scale*, the rater rates an employee’s performance on several performance dimensions on a Likert-type rating scale – e.g., from 1 (poor performance) to 5 (excellent performance). An advantage of graphic rating scales is that they’re easy to construct; a disadvantages is that they’re vulnerable to rater biases.

(c) *Behaviorally anchored rating scales* (BARS) are a type of graphic rating scale in which each point on a scale is “anchored” with a description of a specific behavior. A distinguishing characteristic of BARS is their development, which involves having job incumbents, supervisors, and other subject matter experts identify essential dimensions of job performance and specific behaviors for each dimension that are associated with good, average, and poor performance. Advantages of BARS are that the behavioral anchors help reduce rater biases and provide information that’s useful for employee feedback. Disadvantages are that they’re time-consuming to develop and job-specific. 

3. **Ultimate versus Actual Performance Measures:** Descriptions of job performance measures often distinguish between ultimate and actual criteria. The ultimate criterion is an ideal measure that assesses all of the important contributors to job performance, while the actual criterion is what a job performance measure actually measures. Criterion deficiency and criterion contamination are two reasons for the gap between ultimate and actual criteria: *Criterion deficiency* refers to aspects of performance that are not assessed by the criterion.  For instance, a job knowledge test for clinical psychologists would be deficient if it includes questions on psychopathology and clinical psychology but not ethics. *Criterion contamination* occurs when the criterion measure is affected by factors unrelated to job performance – for example, when a supervisor’s ratings of employees on the criterion are affected by an employee’s gender or race or by the supervisor’s knowledge of how well the employee did on the predictors that were used to hire him or her.
**Performance Assessment – Rater Biases:** Distribution errors, the halo error, the contrast error, and the similarity bias are rater biases that can affect the accuracy of subjective performance ratings.

(a) *Distribution errors* occur when raters consistently use only one part of the rating scale when rating all employees: The central tendency bias occurs when the rater consistently gives all employees average ratings regardless of their actual performance. The leniency and strictness biases occur when the rater consistently gives all employees high ratings or low ratings, respectively, regardless of their actual performance.

(b) The *halo error* is also known as the halo effect and halo bias. It occurs when a rater’s rating of an employee on one dimension of job performance affects how the rater rates the employee on all other dimensions, even when they’re unrelated to that dimension. The halo error can be positive or negative:  A supervisor’s ratings are affected by a positive halo error when the supervisor highly values cooperation and rates employees who are very cooperative high on all dimensions of job performance and is affected by a negative halo error when the supervisor rates employees who are uncooperative low on all dimensions of performance.

(c) The *contrast error* occurs when a rater’s ratings of an employee are affected by the performance of a previously evaluated employee. For example, a supervisor’s ratings are affected by the contrast error when the supervisor gives an average employee below average ratings because she rated an excellent employee immediately before rating the average employee.

(d) The *similarity bias* occurs when raters give higher ratings to ratees they perceive to be similar to themselves.
Methods for reducing rater biases include using relative rating scales, anchoring points on an absolute rating scale with descriptions of specific job behaviors, and providing raters with adequate training. Using relative (rather than absolute) rating scales is most useful for eliminating distribution errors (central tendency, leniency, and strictness biases) since relative scales require raters to give some employees higher or lower ratings than they give to other employees. Anchoring points on an absolute rating scale with descriptions of specific job behaviors helps reduce distribution errors and other biases by clarifying the meaning of each point on the scale. And providing adequate rater training is the best way to reduce rater biases as well as other factors that decrease rater accuracy on relative and absolute rating scales. Note that the research has found that focusing only on rater biases during training can actually reduce overall accuracy and that a better approach is to provide *frame-of-reference (FOR) training* (Guion, 1998). It includes ensuring that trainees understand the multidimensional nature of job performance and the organization’s definition of successful and unsuccessful performance and giving trainees opportunities to practice assigning ratings and receive feedback about their rating accuracy.
