# Employee Selection – Evaluation of Techniques


Before using a new selection technique to make hiring decisions, it must be evaluated to determine if it has adequate reliability and validity, will increase decision-making accuracy, will not have an adverse impact, and has adequate utility.

1. **Reliability and Validity:** Reliability and validity are two standards that are used to judge the adequacy of a predictor. *Reliability* refers to the degree to which a predictor is free from the effects of measurement (random) error and, as a result, provides consistent scores. The various methods for evaluating reliability assess the consistency of scores over time, across different forms or items, or across different scorers, and most produce a reliability coefficient, which is a type of correlation coefficient. The reliability coefficient ranges from 0 to 1.0 and, the closer the coefficient is to 1.0, the less the effect of measurement error and the greater the consistency of scores.

Knowing that a predictor is reliable only indicates that, whatever the predictor measures, it does so consistently. To determine if the predictor actually measures what it was designed to measure, its validity must be assessed. There are three main types of validity and each type is evaluated using different methods. For many predictors used to make selection and other employment decisions, more than one type of validity is evaluated.
(a) *Content validity* refers to the extent to which a predictor adequately samples the knowledge or skills it’s intended to measure. Basing a predictor’s content on the results of a job analysis and having subject matter experts review the content help ensure that it has an acceptable level of content validity. Job knowledge tests and work samples should have adequate content validity.

(b) *Construct validity* refers to the extent to which a predictor measures the construct (hypothetical trait) it was designed to measure. A predictor’s construct validity is assessed in several ways including correlating scores on the predictor with scores on valid measures of the same, similar, and different constructs. Intelligence tests and personality tests should have adequate construct validity. 

(c) *Criterion-related validity* refers to the degree to which scores on the predictor correlate with scores on the criterion. It’s evaluated by correlating predictor and criterion scores obtained by individuals in a tryout sample to obtain a criterion-related validity coefficient. This coefficient ranges from -1.0 to +1.0 and, the closer it is to 0, the lower the predictor’s criterion-related validity. When an organization’s goal is to use applicants’ scores on a predictor to estimate or predict their scores on the criterion to facilitate hiring decisions, it would be important to assess the predictor’s criterion-related validity.

Additional information about reliability and validity is provided in the Test Construction questions and content summaries.  
2. **Incremental Validity:** Incremental validity refers to the increase in decision-making accuracy that occurs by adding a new selection technique (predictor) to the existing selection procedure. A predictor is most likely to increase decision-making accuracy when its criterion-related validity coefficient is large. However, even when a predictor’s validity coefficient is low to moderate, it can have incremental validity when the selection ratio is low and the base rate is moderate:

(a) The *selection ratio* is the percent of job applicants the company plans to hire and is calculated by dividing the number of applicants that will be hired by the total number of applicants. For example, a selection ratio of .10 is low and means that one of 10 applicants will be hired, while a selection ratio of .90 is high and means that nine of 10 applicants will be hired.  A low selection ratio is best because it means the company has more applicants to choose from.
(b) The *base rate* is the percent of employees who were hired using the current selection procedure and are considered successful. A moderate base rate (around .50) is associated with the greatest increase in decision-making accuracy because, when the base rate is high, adding a new predictor probably won’t have much effect since the current procedure is adequate. And when the base rate is low, this suggests that something other than the selection procedure (e.g., inadequate training) is the problem because it’s not likely that use of the current procedure results in choosing the least suitable applicants.
The *Taylor-Russell tables* are used to obtain an estimate of a predictor’s incremental validity for various combinations of criterion-related validity coefficients, base rates, and selection ratios. For example, when a predictor’s criterion-related validity coefficient is .30 (a fairly low coefficient), the base rate is .50 (50% of current employees are successful), and the selection ratio is .10 (one of every 10 applicants will be hired), the Taylor-Russell tables indicate that the addition of the new predictor will result in 71% of hired employees being successful. This means that there will be a 21% increase in successful employees when the new predictor is added to the current selection procedure (71% - 50% = 21%).

3. **Adverse Impact:** Adverse impact is also referred to as disparate impact and is “a type of unfair discrimination in which the result of using a particular personnel selection method has a negative effect on protected group members compared with majority group members” (Muchinsky, 2012, p. 138). Adverse impact is addressed in the Uniform Guidelines on Employee Selection Procedures, which was adopted in 1978 by the Equal Employment Opportunities Commission (EEOC) and other government agencies responsible for enforcing equal employment opportunity laws. The Uniform Guidelines on Employee Selection Procedures (1978) and Uniform Guidelines on Employee Selection Procedures Interpretation and Clarification (1979) describe test unfairness and differential validity as situations that can cause adverse impact:

(a) *Test unfairness* occurs when members of one group consistently obtain lower scores on a selection test or other employment procedure but the score difference is not reflected in differences in scores on a measure of job performance. Test unfairness is occurring when men and women receive similar ratings on a measure of job performance but, for some reason, women consistently obtain lower scores on the selection test and, as a result, are hired less frequently than men are when the test is used to make hiring decisions.

(b) *Differential validity* occurs when a selection test or other employment procedure has significantly different validity coefficients for members of different groups. A selection test has differential validity, for instance, when its criterion-related validity coefficient is .70 for men but .20 for women.
The Uniform Guidelines describes the 80% rule (also known as the four-fifths rule) as a method for determining if a selection test is having an adverse impact. When using the 80% rule, adverse impact is occurring when the hiring rate for a legally protected group is less than 80% of the hiring rate for the majority group. As an example, if the hiring rate for White applicants is 70%, the minimum hiring rate for African-American applicants is 56% (.70 times .80 = .56).

When the court determines that a selection test or other employment procedure is having an adverse impact, an employer has several options: The employer can replace the procedure with another procedure that does not have an adverse impact, modify the procedure so it no longer has an adverse impact, or demonstrate that there is no alternative procedure available that would not have an adverse impact and that use of the procedure is job-related. Job-relatedness is established by showing that the procedure is valid, a business necessity, or a bona fide occupational qualification (Gatewood, Feild, & Barrick, 2016): An employment procedure is considered valid when there is adequate evidence of its criterion-related, content, or construct validity. An employment procedure or requirement is a business necessity when it is necessary for the safe and efficient operation of the business. As an example, a company may discriminate against people with certain physical disabilities if, because of the nature of the job, their disabilities are likely to cause safety risks for employees or customers. An employment procedure or requirement is a bona fide occupational qualification (BFOQ) when it is necessary for maintaining normal business operations. BFOQ may apply to gender, age, religion, and national origin but not race. For example, religion is a BFOQ when a religious high school requires faculty to be members of its denomination.

4. **Utility Analysis:** *Utility analysis* is a method for evaluating “the economic return on investment of human resource interventions such as staffing and training” (Landy & Conte, 2016, p. 282). A commonly cited formula for assessing the utility of selection tests is the Brogden-Cronbach-Gleser formula (Brogden, 1949; Cronbach & Gleser, 1965), which estimates utility in dollars based on several factors, including the number of individuals hired, the test’s validity coefficient, the standard deviation of job performance in dollars, and the cost of testing.    

